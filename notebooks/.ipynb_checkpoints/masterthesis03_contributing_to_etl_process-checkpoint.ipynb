{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020035ed",
   "metadata": {},
   "source": [
    "# Data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6950d8c",
   "metadata": {},
   "source": [
    "As my work progressed in the masters program, it became evident that many datasets I was interested in using had either issues in how they were structured, or contained information that I did not know how to handle.  \n",
    "Thomas Stoeger, a fellow lab mate, had done extensive work with the Enterprise Data Warehousing team (EDW) to better understand tables/datasets in the unified database of the project. He taught me about encoding assumptions and insights about what each table was or was not about in the form of assertion functions. Once I learned a fact or a quirk about a table, I would then write code enforcing such expected behavior from the table, so that future versions of the data could be checked against this expectation.  \n",
    "And as such, one could better document whenever changes occurred as being errors in the ETL process, or whether the datasets switched specification.  \n",
    "Thomas had already written extensive lines of code to assert behaviors from many tables. As he slowly phased out from this project, and I became interested in two particular datasets, I added functions to his giant .py file. Below you can see both functions, which are long, but neat versions of functions that took months to build due to the back and forth with the EDW team and clinicians. These are now under routine use by others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b54b4",
   "metadata": {},
   "source": [
    "### Asserting the basic_endpoints table  \n",
    "This table was hailed as the source of truth for getting dates. When I checked, there are some issues with them (ICU dates falling outside the hospitalization window, and inconsistent calculation of lengths of stay). This function tests initial and then subsequent assumptions on basic_endpoints, as me and others learned more about this table. Notice how whenever an assumption would not hold, a link to the pertinent GitHub issue would be mentioned: It mainly signals an ongoing, unresolved issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_basic_endpoints(df, input_version, org, output_folder):\n",
    "\n",
    "    n_trans = 'clinical.clinical_metadata'\n",
    "    df_trans = get_clean(n_trans, input_version, org)\n",
    "\n",
    "    trans = df_trans[['case_number', 'discharge_disposition_name']].copy(\n",
    "    ).drop_duplicates()\n",
    "    cis = df[['case_number', 'discharge_disposition_name']].drop_duplicates()\n",
    "\n",
    "    tog = pd.merge(cis, trans, on='case_number',\n",
    "                   how='outer', suffixes=('_cis', '_trans'))\n",
    "\n",
    "    # basic_endpoints has \"None\" for empty disposition names\n",
    "    # However, clinical_metadata has \"unknown\" for those entries\n",
    "    tog = tog.replace({'unknown': None})\n",
    "\n",
    "    tog[['discharge_disposition_name_cis', 'discharge_disposition_name_trans']] = tog[[\n",
    "        'discharge_disposition_name_cis', 'discharge_disposition_name_trans']].fillna('')\n",
    "    tog['discharge_disposition_name_cis'] = tog['discharge_disposition_name_cis'].str.strip()\n",
    "    tog['discharge_disposition_name_trans'] = tog['discharge_disposition_name_trans'].str.strip()\n",
    "\n",
    "    f = tog['discharge_disposition_name_cis'] != tog['discharge_disposition_name_trans']\n",
    "    if any(f):\n",
    "\n",
    "        report(\n",
    "            tog[f],\n",
    "            output_folder,\n",
    "            'issue_158_basic_endpoints_disposition_differs_from_clinical_metadata')\n",
    "\n",
    "        print(\"\"\"\n",
    "        https://github.com/NUSCRIPT/script_etl_eda/issues/158\n",
    "        {} records with different discharge_disposition_name in basic_endpoints\n",
    "        and clinical_metadata\n",
    "        \"\"\".format(sum(f)))\n",
    "\n",
    "    # One row, one patient/case. In the past, duplicate records would only differ in consent_dt column\n",
    "    # Code below the first AssertionError checks if that's the only column that differs between duplicates.\n",
    "\n",
    "    if df['case_number'].value_counts().max() > 1:\n",
    "        raise AssertionError(\n",
    "            \"A single case_number/pt_study_id appears in more than one row (potential duplicate record)\")\n",
    "\n",
    "    f = df['discharge_disposition_name'] == 'Expired'\n",
    "    expired = df.loc[f, ['death_date', 'discharge_disposition_name']]\n",
    "    g = expired['death_date'].isnull()\n",
    "\n",
    "    if sum(g) > 0:\n",
    "        raise AssertioError(\n",
    "            f\"There are {sum(g)} 'Expired' cases without a death date\")\n",
    "\n",
    "    # Third intubation dates come after second intubation dates, and second after first\n",
    "\n",
    "    df_two_intub = df.loc[df['Second_intub_start'].notnull()]\n",
    "    f = df_two_intub['Second_intub_start'] >= df_two_intub['First_intub_stop']\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{~f} second intubation start dates happened before the end of the first intubation\")\n",
    "\n",
    "    df_three_intub = df.loc[df['Third_intub_start'].notnull()]\n",
    "    g = df_three_intub['Third_intub_start'] >= df_three_intub['Second_intub_stop']\n",
    "\n",
    "    if not g.all():\n",
    "        raise AssertionError(\n",
    "            f\"{g} third intubation start dates happened before the end of the second intubation\")\n",
    "\n",
    "    # If any of the hospital or ICU dates is NULL, then corresponding LOS should be NULL as well\n",
    "\n",
    "    date_los_pairs = {'hospital_los_days': ['admission_datetime', 'discharge_datetime'],\n",
    "                      'index_ICU_LOS_Days': ['index_icu_start', 'index_icu_stop']}\n",
    "\n",
    "    for los, dates in date_los_pairs.items():\n",
    "        for date in dates:\n",
    "            df_null_time = df.loc[df[date].isnull()]\n",
    "            f = df_null_time[date].isnull()\n",
    "            g = df_null_time[los].isnull()\n",
    "\n",
    "            if sum(f) != sum(g):\n",
    "                raise AssertionError(\n",
    "                    \"At least one record may report a LOS while having a NULL date\")\n",
    "\n",
    "    # ICU start and end dates are within hospital dates\n",
    "\n",
    "    df_start = df[['case_number', 'admission_datetime',\n",
    "                   'index_icu_start']].dropna()\n",
    "    f = df_start['index_icu_start'].dt.date >= df_start['admission_datetime'].dt.date\n",
    "    if not all(f):\n",
    "        p = (~f).sum()\n",
    "        raise AssertionError(f\"For {p} patient(s) the index ICU start is before hospital admission\")\n",
    "\n",
    "    df_start1 = df[['case_number',\n",
    "                    'admission_datetime', 'icu_start2']].dropna()\n",
    "    m = df_start1['icu_start2'].dt.date >= df_start1['admission_datetime'].dt.date\n",
    "    if not all(m):\n",
    "        p = (~m).sum()\n",
    "        raise AssertionError(f\"For {p} patient(s) the second ICU start is before hospital admission\")\n",
    "\n",
    "    df_stop = df[['case_number', 'discharge_datetime',\n",
    "                  'index_icu_stop']].dropna()\n",
    "    g = df_stop['index_icu_stop'].dt.date <= df_stop['discharge_datetime'].dt.date\n",
    "    if not all(g):\n",
    "        q = (~g).sum()\n",
    "        raise AssertionError(f\"For {q} patient(s) the index ICU stop date is after hospital discharge\")\n",
    "\n",
    "    df_stop1 = df[['case_number', 'discharge_datetime', 'icu_stop2']].dropna()\n",
    "    n = df_stop1['icu_stop2'].dt.date <= df_stop1['discharge_datetime'].dt.date\n",
    "    if not all(n):\n",
    "        q = (~n).sum()\n",
    "        raise AssertionError(f\"For {q} patient(s) the second ICU stop date is after hospital discharge\")\n",
    "\n",
    "    # Length of stay (LOS) calculations follow a similar, agreed-upon convention\n",
    "\n",
    "    conventions = []\n",
    "\n",
    "    for los, dates in date_los_pairs.items():\n",
    "        df_time = df.loc[df[dates[0]].notnull()]\n",
    "        df_time = df_time.loc[df_time[dates[1]].notnull()]\n",
    "\n",
    "        number_of_valid_records = len(df_time[los])\n",
    "\n",
    "        df_time['calculated_LOS'] = (df_time[dates[1]].dt.date -\n",
    "                                     df_time[dates[0]].dt.date).dt.days\n",
    "\n",
    "        difference = df_time[los] - df_time['calculated_LOS']\n",
    "        c = difference.value_counts()\n",
    "\n",
    "        if (c != number_of_valid_records).any():\n",
    "            raise AssertionError(\"Inconsistent hospital/ICU LOS calculation\")\n",
    "        else:\n",
    "            conventions.append(list(c.index.astype(int))[0])\n",
    "\n",
    "    if conventions[0] != conventions[1]:\n",
    "        raise AssertionError(\n",
    "            f\"\"\"Inconsistent LOS calculation convention between hospital LOS and ICU LOS\\nHospital admission date is Day {conventions[0]}\\nICU start date is Day {conventions[1]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932f7f2",
   "metadata": {},
   "source": [
    "### Asserting the SOFA scores table  \n",
    "This dataset was difficult to pin down. While luckily only one problem would be found at a time, they usually involved researching and understanding the medical technicalities of the score. For example, to properly assess a score for hypertension/cardiovascular, an epinephrine or dobutamine dose had to be specified if the patient had low mean arterial pressure. When accounting for that, it was still problematic. But Anna from the EDW team realized that she had neglected to further specify that such dosage had to be sustained for a full 60 minutes, otherwise it did not count toward the subscore. Remarkably, physicians didn't capture this technicality either. Once this aspect was accounted for, the table passed all checks regarding validity of the score calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_sofa_scores(df, output_folder):\n",
    "    \"\"\"\n",
    "    Checking the following assumptions:\n",
    "    - ICU starting and ending dates are within hospital admission and discharge dates.\n",
    "    - Day bucket ends minus day bucket starts should define a single day. Not two days. Nor zero.\n",
    "    - If measurements are present, they should conform to SOFA criteria\n",
    "    - The total SOFA score is indeed the sum of scores from each organ system (where NULL values are assumed to be zero).\n",
    "    \"\"\"\n",
    "\n",
    "    # ICU starting and ending dates are within hospital admission and discharge dates.\n",
    "    f = df['icu_start_dt'].dt.date >= df['admission_datetime'].dt.date\n",
    "    if not f.all():\n",
    "\n",
    "        report(df.loc[~f, :][['icu_start_dt', 'admission_datetime']].drop_duplicates(),\n",
    "               output_folder,\n",
    "               'issue_130a_sofa_scores_icu_start_date_before_admission_date')\n",
    "\n",
    "        print(\"\"\"https://github.com/NUSCRIPT/script_etl_eda/issues/130\n",
    "        {} records have a ICU start date that is before hospital admission date\"\"\".format(sum(~f)))\n",
    "\n",
    "    g = df['icu_stop_dt'].dt.date <= df['discharge_datetime'].dt.date\n",
    "    if not g.all():\n",
    "\n",
    "        report(df.loc[~g, :][['icu_stop_dt', 'discharge_datetime']].drop_duplicates(),\n",
    "               output_folder,\n",
    "               'issue_130b_sofa_scores_icu_stop_date_after_discharge_date')\n",
    "\n",
    "        print(\"\"\"https://github.com/NUSCRIPT/script_etl_eda/issues/130\n",
    "        {} records have a ICU stop date that is after hospital discharge date\"\"\".format(sum(~g)))\n",
    "\n",
    "    # Day bucket ends minus day bucket starts should define a single day. Not two days. Nor zero.\n",
    "    h = (df['day_bucket_ends'].dt.date -\n",
    "         df['day_bucket_starts'].dt.date).dt.days == 1\n",
    "    if not h.all():\n",
    "        raise AssertionError(f\"{~h} bucket days does not define a single day\")\n",
    "\n",
    "    # If measurements are present, they should conform to SOFA criteria\n",
    "    # Coagulation criteria/Platelets\n",
    "    df_coag = df[df['Platelet'] > 150]\n",
    "    f = df_coag['platelet_points'] == 0\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} platelet count above 150 was not coded as 0\")\n",
    "\n",
    "    df_coag = df[(df['Platelet'] <= 150) & (df['Platelet'] > 100)]\n",
    "    f = df_coag['platelet_points'] == 1\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} platelet count between 100 and 150 was not coded as 1\")\n",
    "\n",
    "    df_coag = df[(df['Platelet'] <= 100) & (df['Platelet'] > 50)]\n",
    "    f = df_coag['platelet_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} platelet count between 50 and 100 was not coded as 2\")\n",
    "\n",
    "    df_coag = df[(df['Platelet'] <= 50) & (df['Platelet'] > 20)]\n",
    "    f = df_coag['platelet_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} platelet count between 20 and 50 was not coded as 3\")\n",
    "\n",
    "    df_coag = df[df['Platelet'] <= 20]\n",
    "    f = df_coag['platelet_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} platelet count below 20 was not coded as 4\")\n",
    "\n",
    "    df_coag = df[df['Platelet'].isnull()]\n",
    "    f = df_coag['platelet_points'].isnull()\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} NULL platelet count does not correspond with NULL platelet points\")\n",
    "\n",
    "    # Respiratory criteria/PF ratio\n",
    "    df_PF = df[df['PF_ratio'] > 400]\n",
    "    f = df_PF['P_F_ratio_points'] == 0\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} PF_ratio value above 400 mm Hg was not coded as 0\")\n",
    "\n",
    "    df_PF = df[(df['PF_ratio'] <= 400) & (df['PF_ratio'] > 300)]\n",
    "    f = df_PF['P_F_ratio_points'] == 1\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} PF_ratio value between 300 and 400 mm Hg was not coded as 1\")\n",
    "\n",
    "    df_PF = df[(df['PF_ratio'] <= 300) & (df['PF_ratio'] > 200)]\n",
    "    f = df_PF['P_F_ratio_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} PF_ratio value between 200 and 300 mm Hg was not coded as 2\")\n",
    "\n",
    "    df_PF = df[(df['PF_ratio'] <= 200) & (\n",
    "        df['PF_ratio'] > 100) & (df['intub_flag'] == 1)]\n",
    "    f = df_PF['P_F_ratio_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} PF_ratio value between 100 and 200 mm Hg (with respiratory support) was not coded as 3\")\n",
    "\n",
    "    df_PF = df[(df['PF_ratio'] <= 100) & (df['intub_flag'] == 1)]\n",
    "    f = df_PF['P_F_ratio_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} PF_ratio value below 100 mm Hg (with respiratory support) was not coded as 4\")\n",
    "\n",
    "    df_PF = df[df['PF_ratio'].isnull()]\n",
    "    f = df_PF['P_F_ratio_points'].isnull()\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} NULL P/F ratio value does not correspond with NULL PF ratio points\")\n",
    "\n",
    "    # Renal criteria: Creatinine or urine output\n",
    "    df_renal = df[(df['creatinine'] < 1.2) & (\n",
    "        df['HD_or_CRRT_flag'].isnull()) & (df['urine_output'] >= 500)]\n",
    "    f = df_renal['renal_points'] == 0\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} creatinine value below 1.2 mg/dL was not coded as 0\")\n",
    "\n",
    "    df_renal = df[(df['creatinine'] <= 1.9) & (df['creatinine'] >= 1.2) & (\n",
    "        df['HD_or_CRRT_flag'].isnull()) & (df['urine_output'] >= 500)]\n",
    "    f = df_renal['renal_points'] == 1\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} creatinine value between 1.2 and 1.9 mg/dL was not coded as 1\")\n",
    "\n",
    "    df_renal = df[(df['creatinine'] <= 3.4) & (df['creatinine'] >= 2.0) & (\n",
    "        df['HD_or_CRRT_flag'].isnull()) & (df['urine_output'] >= 500)]\n",
    "    f = df_renal['renal_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            \"{sum(~f)} creatinine value between 2.0 and 3.4 mg/dL was not coded as 2\")\n",
    "\n",
    "    df_renal = df[((df['creatinine'] <= 4.9) & (df['creatinine'] >= 3.5) & (\n",
    "        df['urine_output'] >= 200)) & (df['HD_or_CRRT_flag'].isnull())]\n",
    "    f = df_renal['renal_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} creatinine value between 3.5 and 4.9 mg/dL, or urine output value between 200-500 mL/d was not coded as 3\")\n",
    "\n",
    "    df_renal = df[((df['creatinine'] >= 5.0) | (\n",
    "        df['urine_output'] < 200)) & (df['HD_or_CRRT_flag'] == 1)]\n",
    "    f = df_renal['renal_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} creatinine value greater than or equal to 5.0 mg/dL, or urine output value below 200 mL/d was not coded as 4\")\n",
    "\n",
    "    df_renal = df[df['urine_output'].isnull() & df['creatinine'].isnull()\n",
    "                  & df['HD_or_CRRT_flag'].isnull()]\n",
    "    f = df_renal['renal_points'].isnull()\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} NULL value for urine output and creatinine does not correspond with NULL renal points\")\n",
    "\n",
    "    # Neurological criteria/Glasgow Coma Scale\n",
    "    cols = ['eye_opening_score', 'best_motor_response_score',\n",
    "            'best_verbal_response_score']\n",
    "    df_for_gcs = df.dropna(subset=cols).copy()\n",
    "    for col in cols:\n",
    "        df_for_gcs.loc[:, col] = df_for_gcs.loc[:, col].astype(int)\n",
    "    \n",
    "    df_for_gcs['total_gcs_score'] = df_for_gcs['eye_opening_score'] + \\\n",
    "        df_for_gcs['best_motor_response_score'] + df_for_gcs['best_verbal_response_score']\n",
    "    df_gcs = df_for_gcs[df_for_gcs['total_gcs_score'] == 15]\n",
    "    f = df_gcs['gcs_points'] == 0\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} total GCS score of 15 was not coded as 0\")\n",
    "\n",
    "    df_gcs = df_for_gcs[(df_for_gcs['total_gcs_score'] == 13) | (df_for_gcs['total_gcs_score'] == 14)]\n",
    "    f = df_gcs['gcs_points'] == 1\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} total GCS score between 13 and 14 (inclusive) was not coded as 1\")\n",
    "\n",
    "    df_gcs = df_for_gcs[(df_for_gcs['total_gcs_score'] <= 12) & (df_for_gcs['total_gcs_score'] >= 10)]\n",
    "    f = df_gcs['gcs_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} total GCS score between 10 and 12 (inclusive) was not coded as 2\")\n",
    "\n",
    "    df_gcs = df_for_gcs[(df_for_gcs['total_gcs_score'] <= 9) & (df_for_gcs['total_gcs_score'] >= 6)]\n",
    "    f = df_gcs['gcs_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} total GCS score between 6 and 9 (inclusive) was not coded as 3\")\n",
    "\n",
    "    df_gcs = df_for_gcs[df_for_gcs['total_gcs_score'] < 6]\n",
    "    f = df_gcs['gcs_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{~f} total GCS score less than 6 was not coded as 4\")\n",
    "\n",
    "    df_gcs = df_for_gcs[df_for_gcs['eye_opening_score'].isnull() | df_for_gcs['best_motor_response_score'].isnull(\n",
    "    ) | df_for_gcs['best_verbal_response_score'].isnull()]\n",
    "    f = df_gcs['gcs_points'].isnull()\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} NULL GCS subscore field does not correspond with NULL GCS points\")\n",
    "\n",
    "    # Cardiovascular criteria/Mean arterial pressure\n",
    "    df_htn = df[(df['map'] >= 70) & (\n",
    "        df['dosage'].isnull() | df['dosage'] == 0)]\n",
    "    f = df_htn['htn_points'] == 0\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} MAP value greater than or equal to 70 mm Hg was not coded as 0\")\n",
    "\n",
    "    df_htn = df[(df['map'] < 70) & (df['dosage'].isnull() | df['dosage'] == 0)]\n",
    "    f = df_htn['htn_points'] == 1\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} MAP value smaller than 70 mm Hg was not coded as 1\")\n",
    "\n",
    "    g = df['htn_med_name'] == 'dopamine'\n",
    "    h = df['htn_med_name'] == 'EPINEPHrine'\n",
    "    j = df['htn_med_name'] == 'DOBUTamine'\n",
    "    df_htn_dop = df.loc[g]\n",
    "    df_htn_epi = df.loc[h]\n",
    "    df_htn_dobu = df.loc[j]\n",
    "\n",
    "    df_htn = df_htn_dop[(df_htn_dop['dosage'] > 0) & (df_htn_dop['dosage'] < 5) & (\n",
    "        df_htn_dop['length_of_time_on_med_in_min'] >= 60)]\n",
    "    f = df_htn['htn_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} dopamine value smaller than 5 ug/kg/min was not coded as 2\")\n",
    "\n",
    "    f = df_htn_dobu['htn_points'] == 2\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} entry where dobutamine was administered was not coded as 2\")\n",
    "\n",
    "    df_htn = df_htn_dop[(df_htn_dop['dosage'] <= 15) & (\n",
    "        df_htn_dop['dosage'] >= 5.1) & (df_htn_dop['length_of_time_on_med_in_min'] >= 60)]\n",
    "    f = df_htn['htn_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(f\"{sum(~f)} dopamine value between 5.1 and 15 ug/kg/min (inclusive) was not coded as 3\")\n",
    "\n",
    "    df_htn = df_htn_epi[(df_htn_epi['dosage'] > 0) & (df_htn_epi['dosage'] <= 0.1) & (\n",
    "        df_htn_epi['length_of_time_on_med_in_min'] >= 60)]\n",
    "    f = df_htn['htn_points'] == 3\n",
    "\n",
    "    if not f.all():\n",
    "        print(\"\"\" \n",
    "        epinephrine encoding wrong. need to ask felix to add more specific error report\n",
    "        \n",
    "        \"\"\")\n",
    "\n",
    "    df_htn = df_htn_dop[(df_htn_dop['dosage'] > 15) & (\n",
    "        df_htn_dop['length_of_time_on_med_in_min'] >= 60)]\n",
    "    f = df_htn['htn_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} dopamine value greater than 15 ug/kg/min was not coded as 4\")\n",
    "\n",
    "    df_htn = df_htn_epi[(df_htn_epi['dosage'] > 0.1) & (\n",
    "        df_htn_epi['length_of_time_on_med_in_min'] >= 60)]\n",
    "    f = df_htn['htn_points'] == 4\n",
    "\n",
    "    if not f.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~f)} epinephrine value greater than 0.1 ug/kg/min was not coded as 4\")\n",
    "\n",
    "    # The total SOFA score is indeed the sum of scores from each organ system (where NULL values are assumed to be zero).\n",
    "    individual_sums = df['P_F_ratio_points'].fillna(0) + df['platelet_points'].fillna(0) + df['bilirubin_points'].fillna(\n",
    "        0) + df['htn_points'].fillna(0) + df['gcs_points'].fillna(0) + df['renal_points'].fillna(0)\n",
    "    h = individual_sums == df['SOFA']\n",
    "\n",
    "    if not h.all():\n",
    "        raise AssertionError(\n",
    "            f\"{sum(~h)} SOFA score doesn't correspond with the sum of individual scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
